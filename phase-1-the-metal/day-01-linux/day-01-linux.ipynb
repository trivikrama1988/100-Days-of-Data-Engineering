{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Day 1: The Physics of Data ‚Äî Interactive Lab**\n",
    "\n",
    "**User Profile:** Senior Data Engineer  \n",
    "**Objective:** Stop treating the OS as a black box. In this notebook, we will use **Bash** (to inspect the Kernel) and **Python** (to implement specific I/O patterns) side-by-side.\n",
    "\n",
    "### **Core Concepts:**\n",
    "1. **Inodes:** The physical identity of a file.\n",
    "2. **Kernel Metrics:** Reading `/proc` to see what the OS is thinking.\n",
    "3. **System Limits:** Crashing the `ulimit`.\n",
    "4. **I/O Physics:** 1 Byte vs 4KB vs Memory Mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üê£ Level 1: Beginner (The Basics)**\n",
    "**Goal:** Prove that filenames are just labels and the OS uses Integers (Inodes & FDs) to track data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example 1: The Inode Identity**\n",
    "**Theory:** If you create a \"Hard Link\", you have two filenames pointing to the **same** physical Inode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"--- [Bash] Inspecting Inodes ---\"\n",
    "# 1. Create a file\n",
    "echo \"I am physical data on the disk.\" > /tmp/inode_demo.txt\n",
    "\n",
    "# 2. Create a Hard Link (A second pointer to the same data)\n",
    "ln /tmp/inode_demo.txt /tmp/inode_link.txt\n",
    "\n",
    "# 3. Show Inode Numbers (-i flag)\n",
    "# Notice the first column is IDENTICAL\n",
    "ls -li /tmp/inode_demo.txt /tmp/inode_link.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"--- [Python] Verifying Inodes ---\")\n",
    "f1 = \"/tmp/inode_demo.txt\"\n",
    "f2 = \"/tmp/inode_link.txt\"\n",
    "\n",
    "# Get Inode integers\n",
    "inode_1 = os.stat(f1).st_ino\n",
    "inode_2 = os.stat(f2).st_ino\n",
    "\n",
    "print(f\"File 1 Inode: {inode_1}\")\n",
    "print(f\"File 2 Inode: {inode_2}\")\n",
    "\n",
    "if inode_1 == inode_2:\n",
    "    print(\"‚úÖ PROOF: Different names, SAME physical file.\")\n",
    "else:\n",
    "    print(\"‚ùå Failed.\")\n",
    "    \n",
    "# Cleanup\n",
    "if os.path.exists(f1): os.remove(f1)\n",
    "if os.path.exists(f2): os.remove(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example 2: The Kernel Spy (/proc)**\n",
    "**Theory:** Tools like `htop` just read text files in `/proc`. Let's see the **Page Cache** (RAM used to cache disk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"--- [Bash] Reading Kernel Memory Info ---\"\n",
    "# The Kernel exposes memory stats here\n",
    "grep -E \"MemTotal|Cached|Dirty\" /proc/meminfo | head -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- [Python] Parsing Kernel Metrics ---\")\n",
    "\n",
    "def get_kernel_memory():\n",
    "    stats = {}\n",
    "    with open(\"/proc/meminfo\", \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.split(\":\")\n",
    "            if len(parts) == 2:\n",
    "                stats[parts[0].strip()] = parts[1].strip()\n",
    "    return stats\n",
    "\n",
    "mem = get_kernel_memory()\n",
    "print(f\"Total RAM:   {mem.get('MemTotal')}\")\n",
    "print(f\"Page Cache:  {mem.get('Cached')} (Data sitting in RAM)\")\n",
    "print(f\"Dirty Pages: {mem.get('Dirty')} (Data waiting to flush to disk)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üîß Level 2: Intermediate (Mechanics)**\n",
    "**Goal:** Understand System Calls, File Descriptors, and Limits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example 3: The \"Too Many Open Files\" Crash**\n",
    "**Theory:** Every process has a limit (`ulimit -n`). Leaking file handles crashes apps like Kafka or Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"--- [Bash] Checking Limits ---\"\n",
    "echo \"Soft Limit (Process): $(ulimit -n)\"\n",
    "echo \"Hard Limit (Max):     $(ulimit -Hn)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resource\n",
    "\n",
    "print(\"--- [Python] Leaking FDs ---\")\n",
    "soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "print(f\"My Limit: {soft} files\")\n",
    "\n",
    "handles = []\n",
    "try:\n",
    "    # Attempt to open more files than allowed\n",
    "    for i in range(soft + 10):\n",
    "        f = open(\"/dev/null\", \"r\")\n",
    "        handles.append(f)\n",
    "except OSError as e:\n",
    "    print(f\"\\nüí• CRASHED at file #{len(handles)}!\")\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    # Cleanup\n",
    "    for f in handles: f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example 4: The \"Flush\" Latency Trap**\n",
    "**Theory:** Data sits in a User Space Buffer until \"flushed\". This reduces syscalls but adds latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "filename = \"/tmp/latency_test.txt\"\n",
    "\n",
    "print(\"--- [Python] Buffering Demo ---\")\n",
    "with open(filename, \"w\") as f:\n",
    "    f.write(\"Hidden Data\")\n",
    "    size = os.stat(filename).st_size\n",
    "    print(f\"Written to buffer. Size on disk: {size} bytes (Expected 0 or small)\")\n",
    "    \n",
    "    f.flush() # Force write to Kernel\n",
    "    os.fsync(f.fileno()) # Force write to Disk Platter\n",
    "    \n",
    "    size = os.stat(filename).st_size\n",
    "    print(f\"After Flush+Fsync. Size on disk: {size} bytes\")\n",
    "\n",
    "os.remove(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üöÄ Level 3: Advanced (Optimization)**\n",
    "**Goal:** Bypass the kernel overhead for high performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example 5: The Block Size Benchmark**\n",
    "**Theory:** Writing 1 Byte at a time = 1 Million System Calls. Writing 4KB = 250 System Calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"--- [Bash] DD Benchmark ---\"\n",
    "# Write 10MB in 1-byte chunks (Very Slow)\n",
    "echo \"1. Writing 10MB in 1-byte chunks...\"\n",
    "time dd if=/dev/zero of=/tmp/test_1b.dat bs=1 count=500000 2>&1 | grep \"records in\"\n",
    "\n",
    "# Write 10MB in 4KB chunks (Instant)\n",
    "echo \"2. Writing 10MB in 4KB chunks...\"\n",
    "time dd if=/dev/zero of=/tmp/test_4k.dat bs=4096 count=122 2>&1 | grep \"records in\"\n",
    "\n",
    "rm /tmp/test_1b.dat /tmp/test_4k.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"--- [Python] Syscall Benchmark ---\")\n",
    "\n",
    "def benchmark_write(chunk_size, total_bytes=500_000):\n",
    "    filename = f\"/tmp/bench_{chunk_size}.bin\"\n",
    "    data = b'X' * chunk_size\n",
    "    \n",
    "    start = time.time()\n",
    "    with open(filename, \"wb\", buffering=0) as f: # buffering=0 forces Syscall per write\n",
    "        for _ in range(total_bytes // chunk_size):\n",
    "            f.write(data)\n",
    "    return time.time() - start\n",
    "\n",
    "t_1 = benchmark_write(1)\n",
    "t_4k = benchmark_write(4096)\n",
    "\n",
    "print(f\"1 Byte Writes: {t_1:.4f}s\")\n",
    "print(f\"4 KB Writes:   {t_4k:.4f}s\")\n",
    "print(f\"üöÄ Speedup: {t_1/t_4k:.1f}x Faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example 6: Zero-Copy mmap**\n",
    "**Theory:** Bypass the `read()` syscall entirely. Treat the disk file as an array in RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmap\n",
    "import os\n",
    "\n",
    "print(\"--- [Python] Memory Mapping ---\")\n",
    "filename = \"/tmp/mmap_test.dat\"\n",
    "\n",
    "# 1. Create a file\n",
    "with open(filename, \"wb\") as f:\n",
    "    f.write(b\"Hello Kernel World \" * 100)\n",
    "\n",
    "# 2. Map it\n",
    "with open(filename, \"r+b\") as f:\n",
    "    # Map file to memory\n",
    "    mm = mmap.mmap(f.fileno(), 0)\n",
    "    \n",
    "    # Read it like a string (Zero System Calls)\n",
    "    print(f\"First 20 bytes: {mm[:20]}\")\n",
    "    \n",
    "    # Modify directly on disk by changing memory\n",
    "    mm[0:5] = b\"HELLO\"\n",
    "    mm.close()\n",
    "\n",
    "os.remove(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üëë Level 4: Senior/Expert (Architecture)**\n",
    "**Goal:** Replicate Database internals (Pages, ACID)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example 7: The \"Database Page\" Reader**\n",
    "**Theory:** Databases don't read files line-by-line. They jump (`seek`) to specific 8KB \"Pages\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- [Python] DB Page Simulation ---\")\n",
    "PAGE_SIZE = 4096 # 4KB Page\n",
    "filename = \"/tmp/db_data.dat\"\n",
    "\n",
    "# Create dummy DB file (3 Pages)\n",
    "with open(filename, \"wb\") as f:\n",
    "    f.write(b\"Page0...\" + b\"\\0\" * (PAGE_SIZE - 8))\n",
    "    f.write(b\"Page1...\" + b\"\\0\" * (PAGE_SIZE - 8))\n",
    "    f.write(b\"Page2...\" + b\"\\0\" * (PAGE_SIZE - 8))\n",
    "\n",
    "def read_page(page_id):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        # The Senior Move: Seek directly to offset\n",
    "        f.seek(page_id * PAGE_SIZE)\n",
    "        return f.read(8) # Read header only\n",
    "\n",
    "print(f\"Reading Page 1: {read_page(1)}\")\n",
    "print(f\"Reading Page 2: {read_page(2)}\")\n",
    "\n",
    "os.remove(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example 8: Atomic Swap (ACID Basics)**\n",
    "**Theory:** How do you update a file without corrupting it if power fails? Write to temp, then `os.replace` (Atomic Inode Switch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"--- [Bash] Atomic Move ---\"\n",
    "echo \"Old Data\" > /tmp/production.db\n",
    "echo \"New Data\" > /tmp/production.tmp\n",
    "\n",
    "# 'mv' on the same filesystem is atomic\n",
    "# It swaps the Inode pointer instantly\n",
    "mv /tmp/production.tmp /tmp/production.db\n",
    "\n",
    "cat /tmp/production.db\n",
    "rm /tmp/production.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(\"--- [Python] Atomic Replace ---\")\n",
    "db_file = \"/tmp/app_config.json\"\n",
    "tmp_file = \"/tmp/app_config.tmp\"\n",
    "\n",
    "# Initial state\n",
    "with open(db_file, \"w\") as f: f.write('{\"status\": \"running\"}')\n",
    "\n",
    "# 1. Write to Temp (Safe Zone)\n",
    "with open(tmp_file, \"w\") as f:\n",
    "    f.write('{\"status\": \"maintenance\"}')\n",
    "    f.flush()\n",
    "    os.fsync(f.fileno())\n",
    "\n",
    "# 2. Atomic Switch\n",
    "os.replace(tmp_file, db_file)\n",
    "\n",
    "with open(db_file, \"r\") as f:\n",
    "    print(f\"Final Config: {f.read()}\")\n",
    "\n",
    "if os.path.exists(db_file): os.remove(db_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üõ†Ô∏è External Lab Execution**\n",
    "We also have standalone scripts in the `lab/` folder. You can run them directly from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"Running External FD Leak Detector...\"\n",
    "# Note: Ensure you are in the correct directory or provide full path\n",
    "# python3 ../lab/fd_leak_detector.py\n",
    "echo \"(Skipped for safety in notebook, run in terminal)\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}